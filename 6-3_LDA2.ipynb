{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "120049b4",
   "metadata": {},
   "source": [
    "# 잠재 디리클레 할당(LDA) 실습2\n",
    "<ol>\n",
    "    <li>뉴스 기사 제목 데이터에 대한 이해</li>\n",
    "    <li>텍스트 전처리</li>\n",
    "    <li>TF-IDF 행렬 만들기</li>\n",
    "    <li>토픽 모델링</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84716240",
   "metadata": {},
   "source": [
    "## 뉴스 기사 제목 데이터에 대한 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ab880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "#urllib.request.urlretrieve(\"https://raw.githubusercontent.com/franciscadias/data/master/abcnews-date-text.csv\", filename=\"abcnews-date-text.csv\")\n",
    "data = pd.read_csv('abcnews-date-text.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f036eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:20000] #일부만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685d4966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       headline_text\n",
       "0  aba decides against community broadcasting lic...\n",
       "1     act fire witnesses must be aware of defamation\n",
       "2     a g calls for infrastructure protection summit\n",
       "3           air nz staff in aust strike for pay rise\n",
       "4      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = data[['headline_text']]\n",
    "text.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f444221c",
   "metadata": {},
   "source": [
    "## 텍스트 전처리\n",
    "<ol>\n",
    "    <li>불용어 제거</li>\n",
    "    <li>표제어 추출</li>\n",
    "    <li>길이가 짧은 단어 제거</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fcb41f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aba, decides, against, community, broadcastin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[act, fire, witnesses, must, be, aware, of, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[a, g, calls, for, infrastructure, protection,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[air, nz, staff, in, aust, strike, for, pay, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[air, nz, strike, to, affect, australian, trav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[analyst, blames, govt, for, abc, digital, dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[application, for, second, wagga, brothel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[aussie, dollar, hits, new, heights]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[australian, coach, leaves, french, club, brive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[australia, will, always, be, an, al, qaeda, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headline_text\n",
       "0      [aba, decides, against, community, broadcastin...\n",
       "1      [act, fire, witnesses, must, be, aware, of, de...\n",
       "2      [a, g, calls, for, infrastructure, protection,...\n",
       "3      [air, nz, staff, in, aust, strike, for, pay, r...\n",
       "4      [air, nz, strike, to, affect, australian, trav...\n",
       "...                                                  ...\n",
       "19995  [analyst, blames, govt, for, abc, digital, dem...\n",
       "19996         [application, for, second, wagga, brothel]\n",
       "19997               [aussie, dollar, hits, new, heights]\n",
       "19998   [australian, coach, leaves, french, club, brive]\n",
       "19999  [australia, will, always, be, an, al, qaeda, t...\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 토큰화\n",
    "import nltk\n",
    "text['headline_text'] = text.apply(lambda row: nltk.word_tokenize(row['headline_text']), axis=1)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda6fbd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-5c9bd63b69e4>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text['headline_text'] = text['headline_text'].apply(lambda x: [word for word in x if word not in (stop)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aba, decides, community, broadcasting, licence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[act, fire, witnesses, must, aware, defamation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[g, calls, infrastructure, protection, summit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[air, nz, staff, aust, strike, pay, rise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[air, nz, strike, affect, australian, travellers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[analyst, blames, govt, abc, digital, demise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[application, second, wagga, brothel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[aussie, dollar, hits, new, heights]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[australian, coach, leaves, french, club, brive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[australia, always, al, qaeda, target, expert]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headline_text\n",
       "0       [aba, decides, community, broadcasting, licence]\n",
       "1        [act, fire, witnesses, must, aware, defamation]\n",
       "2         [g, calls, infrastructure, protection, summit]\n",
       "3              [air, nz, staff, aust, strike, pay, rise]\n",
       "4      [air, nz, strike, affect, australian, travellers]\n",
       "...                                                  ...\n",
       "19995      [analyst, blames, govt, abc, digital, demise]\n",
       "19996              [application, second, wagga, brothel]\n",
       "19997               [aussie, dollar, hits, new, heights]\n",
       "19998   [australian, coach, leaves, french, club, brive]\n",
       "19999     [australia, always, al, qaeda, target, expert]\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불용어 제거\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "text['headline_text'] = text['headline_text'].apply(lambda x: [word for word in x if word not in (stop)])\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29da6886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-a3ceea11b0b2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text['headline_text'] = text['headline_text'].apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos='v') for word in x])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[aba, decide, community, broadcast, licence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[act, fire, witness, must, aware, defamation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[g, call, infrastructure, protection, summit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[air, nz, staff, aust, strike, pay, rise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[air, nz, strike, affect, australian, travellers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[analyst, blame, govt, abc, digital, demise]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[application, second, wagga, brothel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[aussie, dollar, hit, new, heights]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[australian, coach, leave, french, club, brive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[australia, always, al, qaeda, target, expert]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headline_text\n",
       "0           [aba, decide, community, broadcast, licence]\n",
       "1          [act, fire, witness, must, aware, defamation]\n",
       "2          [g, call, infrastructure, protection, summit]\n",
       "3              [air, nz, staff, aust, strike, pay, rise]\n",
       "4      [air, nz, strike, affect, australian, travellers]\n",
       "...                                                  ...\n",
       "19995       [analyst, blame, govt, abc, digital, demise]\n",
       "19996              [application, second, wagga, brothel]\n",
       "19997                [aussie, dollar, hit, new, heights]\n",
       "19998    [australian, coach, leave, french, club, brive]\n",
       "19999     [australia, always, al, qaeda, target, expert]\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 표제어 추출\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "text['headline_text'] = text['headline_text'].apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos='v') for word in x])\n",
    "text # 3인칭 단수 -> 1인칭, 과거 현재형 동사 -> 현재형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648ce268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                [decide, community, broadcast, licence]\n",
       "1               [fire, witness, must, aware, defamation]\n",
       "2             [call, infrastructure, protection, summit]\n",
       "3                            [staff, aust, strike, rise]\n",
       "4               [strike, affect, australian, travellers]\n",
       "                              ...                       \n",
       "19995            [analyst, blame, govt, digital, demise]\n",
       "19996              [application, second, wagga, brothel]\n",
       "19997                          [aussie, dollar, heights]\n",
       "19998    [australian, coach, leave, french, club, brive]\n",
       "19999         [australia, always, qaeda, target, expert]\n",
       "Name: headline_text, Length: 20000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 길이가 짧은(3이하) 단어 제거\n",
    "tokenized_doc = text['headline_text'].apply(lambda x: [word for word in x if len(word) > 3])\n",
    "tokenized_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b73c9",
   "metadata": {},
   "source": [
    "## TF-IDF 행렬 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35b6464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-0d6fa3090d55>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text['headline_text'] = detokenized_doc # 다시 text['headline_text']에 재저장\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>decide community broadcast licence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fire witness must aware defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>call infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>staff aust strike rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strike affect australian travellers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>analyst blame govt digital demise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>application second wagga brothel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>aussie dollar heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>australian coach leave french club brive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>australia always qaeda target expert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  headline_text\n",
       "0            decide community broadcast licence\n",
       "1            fire witness must aware defamation\n",
       "2         call infrastructure protection summit\n",
       "3                        staff aust strike rise\n",
       "4           strike affect australian travellers\n",
       "...                                         ...\n",
       "19995         analyst blame govt digital demise\n",
       "19996          application second wagga brothel\n",
       "19997                     aussie dollar heights\n",
       "19998  australian coach leave french club brive\n",
       "19999      australia always qaeda target expert\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 역토큰화 (토큰화 작업을 되돌림)\n",
    "detokenized_doc = []\n",
    "for i in range(len(text)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    detokenized_doc.append(t)\n",
    "\n",
    "text['headline_text'] = detokenized_doc # 다시 text['headline_text']에 재저장\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8544f544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 1000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english', \n",
    "max_features= 1000) # 상위 1,000개의 단어를 보존 \n",
    "X = vectorizer.fit_transform(text['headline_text'])\n",
    "X.shape # TF-IDF 행렬의 크기 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93121a",
   "metadata": {},
   "source": [
    "## 토픽 모델링 - LDA 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ccef0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10009995  0.10010818  0.10011588 ...  0.10011054  0.10016133\n",
      "   0.10012603]\n",
      " [ 0.10008226  0.10010319  0.10009765 ...  0.10010516  0.10051457\n",
      "   0.10012813]\n",
      " [ 0.1001514   0.10013558  0.10012901 ...  0.10010288  0.10013559\n",
      "   0.10012032]\n",
      " ...\n",
      " [ 0.10013912  0.10010712 24.49911176 ...  0.10010938  0.10011624\n",
      "   0.10013254]\n",
      " [ 0.10012317  0.1001066   0.10011805 ...  0.10011223  0.10013261\n",
      "   0.1001039 ]\n",
      " [ 0.10010023 47.54413517  0.10011057 ...  0.10009603  0.1001182\n",
      "   0.10315478]]\n",
      "(10, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda_model=LatentDirichletAllocation(n_components=10,\n",
    "                                    learning_method='online',\n",
    "                                    random_state=777,\n",
    "                                    max_iter=1)\n",
    "lda_top=lda_model.fit_transform(X)\n",
    "print(lda_model.components_)\n",
    "print(lda_model.components_.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f7f637d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: [('probe', 98.89), ('crash', 93.62), ('drug', 86.2), ('record', 76.6), ('injure', 75.01)]\n",
      "Topic 2: [('warn', 113.48), ('iraq', 107.39), ('concern', 103.39), ('australia', 86.11), ('world', 82.59)]\n",
      "Topic 3: [('lead', 125.23), ('fight', 95.67), ('continue', 90.19), ('french', 82.81), ('road', 78.45)]\n",
      "Topic 4: [('report', 136.05), ('final', 80.74), ('appeal', 74.56), ('china', 65.73), ('chief', 63.3)]\n",
      "Topic 5: [('police', 185.59), ('urge', 163.69), ('consider', 105.29), ('leave', 92.33), ('defend', 88.29)]\n",
      "Topic 6: [('kill', 156.08), ('return', 98.85), ('test', 96.53), ('case', 80.12), ('minister', 78.5)]\n",
      "Topic 7: [('budget', 173.78), ('govt', 166.77), ('boost', 141.93), ('miss', 99.88), ('change', 98.55)]\n",
      "Topic 8: [('plan', 217.39), ('sars', 169.18), ('charge', 162.03), ('trial', 103.55), ('rise', 97.6)]\n",
      "Topic 9: [('council', 171.44), ('claim', 165.23), ('open', 115.92), ('welcome', 108.06), ('clear', 81.85)]\n",
      "Topic 10: [('face', 180.08), ('fund', 166.62), ('court', 151.09), ('talk', 101.52), ('seek', 96.52)]\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names() # 단어 집합. 1,000개의 단어가 저장됨.\n",
    "\n",
    "def get_topics(components, feature_names, n=5):\n",
    "    for idx, topic in enumerate(components):\n",
    "        print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(2)) for i in topic.argsort()[:-n - 1:-1]])\n",
    "        \n",
    "get_topics(lda_model.components_,terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beff8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
