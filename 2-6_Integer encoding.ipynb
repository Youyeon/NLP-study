{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe34bc6e",
   "metadata": {},
   "source": [
    "# 정수 인코딩(Integer Encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee579e0",
   "metadata": {},
   "source": [
    "## dictionary 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "602bc7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477c98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"A barber is a person. a barber is good person. a barber is huge person. \\\n",
    "he Knew A Secret! The Secret He Kept is huge secret. Huge secret. His barber kept his word. \\\n",
    "a barber kept his word. His barber kept his secret. \\\n",
    "But keeping and keeping such a huge secret to himself was driving the barber crazy. the barber went up a huge mountain.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03e16a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A barber is a person.',\n",
       " 'a barber is good person.',\n",
       " 'a barber is huge person.',\n",
       " 'he Knew A Secret!',\n",
       " 'The Secret He Kept is huge secret.',\n",
       " 'Huge secret.',\n",
       " 'His barber kept his word.',\n",
       " 'a barber kept his word.',\n",
       " 'His barber kept his secret.',\n",
       " 'But keeping and keeping such a huge secret to himself was driving the barber crazy.',\n",
       " 'the barber went up a huge mountain.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 토큰화\n",
    "text = sent_tokenize(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af0cc456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['barber', 'person'],\n",
       " ['barber', 'good', 'person'],\n",
       " ['barber', 'huge', 'person'],\n",
       " ['knew', 'secret'],\n",
       " ['secret', 'kept', 'huge', 'secret'],\n",
       " ['huge', 'secret'],\n",
       " ['barber', 'kept', 'word'],\n",
       " ['barber', 'kept', 'word'],\n",
       " ['barber', 'kept', 'secret'],\n",
       " ['keeping', 'keeping', 'huge', 'secret', 'driving', 'barber', 'crazy'],\n",
       " ['barber', 'went', 'huge', 'mountain']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "sentences = []\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i in text:\n",
    "    sentence = word_tokenize(i) # 문장 하나씩 불러와서 단어 토큰화\n",
    "    result = []\n",
    "    \n",
    "    for word in sentence: # 문장의 단어\n",
    "        word = word.lower()\n",
    "        if word not in stop_words:# 불용어가 아니면\n",
    "            if len(word)>2: # 길이 2이상 (1은 불용어일 가능성이 높음)\n",
    "                result.append(word)\n",
    "                if word not in vocab: #\n",
    "                    vocab[word]=0 # dictionary에 key 삽입\n",
    "                vocab[word] += 1 # 빈도수 증가\n",
    "    sentences.append(result)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c66abd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barber': 8,\n",
       " 'person': 3,\n",
       " 'good': 1,\n",
       " 'huge': 5,\n",
       " 'knew': 1,\n",
       " 'secret': 6,\n",
       " 'kept': 4,\n",
       " 'word': 2,\n",
       " 'keeping': 2,\n",
       " 'driving': 1,\n",
       " 'crazy': 1,\n",
       " 'went': 1,\n",
       " 'mountain': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249d4702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['barber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e9eba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barber', 8),\n",
       " ('secret', 6),\n",
       " ('huge', 5),\n",
       " ('kept', 4),\n",
       " ('person', 3),\n",
       " ('word', 2),\n",
       " ('keeping', 2),\n",
       " ('good', 1),\n",
       " ('knew', 1),\n",
       " ('driving', 1),\n",
       " ('crazy', 1),\n",
       " ('went', 1),\n",
       " ('mountain', 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 빈도수가 높은 순서대로 정렬\n",
    "vocab_sorted = sorted(vocab.items(), key = lambda x:x[1], reverse=True)\n",
    "vocab_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e714bc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barber': 1,\n",
       " 'secret': 2,\n",
       " 'huge': 3,\n",
       " 'kept': 4,\n",
       " 'person': 5,\n",
       " 'word': 6,\n",
       " 'keeping': 7}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 높은 빈도수 -> 낮은 정수 인덱스 부여\n",
    "word_to_index = {}\n",
    "i = 0\n",
    "for (word, frequency) in vocab_sorted:\n",
    "    if frequency>1: # 빈도수가 적은 단어는 제외\n",
    "        i+=1\n",
    "        word_to_index[word]=i\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011e7101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word', 'keeping']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 빈도수 상위 5개만 쓰고싶다면\n",
    "vocab_size = 5\n",
    "words_frequency = [w for w,c in word_to_index.items() if c >= vocab_size + 1] # 인덱스가 5 초과인 단어들\n",
    "for w in words_frequency:\n",
    "    del word_to_index[w]\n",
    "print(words_frequency)\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "726ae33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 집합에 존재하지 않는 단어 = Out-of-Vocabulary (OOV)\n",
    "word_to_index['OOV'] = len(word_to_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a010b5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [1, 6, 5],\n",
       " [1, 3, 5],\n",
       " [6, 2],\n",
       " [2, 4, 3, 2],\n",
       " [3, 2],\n",
       " [1, 4, 6],\n",
       " [1, 4, 6],\n",
       " [1, 4, 2],\n",
       " [6, 6, 3, 2, 6, 1, 6],\n",
       " [1, 6, 3, 6]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = []\n",
    "for s in sentences:\n",
    "    temp = []\n",
    "    for w in s:\n",
    "        try:\n",
    "            temp.append(word_to_index[w])\n",
    "        except KeyError:\n",
    "            temp.append(word_to_index['OOV'])\n",
    "    encoded.append(temp)\n",
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7aaffc",
   "metadata": {},
   "source": [
    "# Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85d191cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b529bb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barber',\n",
       " 'person',\n",
       " 'barber',\n",
       " 'good',\n",
       " 'person',\n",
       " 'barber',\n",
       " 'huge',\n",
       " 'person',\n",
       " 'knew',\n",
       " 'secret',\n",
       " 'secret',\n",
       " 'kept',\n",
       " 'huge',\n",
       " 'secret',\n",
       " 'huge',\n",
       " 'secret',\n",
       " 'barber',\n",
       " 'kept',\n",
       " 'word',\n",
       " 'barber',\n",
       " 'kept',\n",
       " 'word',\n",
       " 'barber',\n",
       " 'kept',\n",
       " 'secret',\n",
       " 'keeping',\n",
       " 'keeping',\n",
       " 'huge',\n",
       " 'secret',\n",
       " 'driving',\n",
       " 'barber',\n",
       " 'crazy',\n",
       " 'barber',\n",
       " 'went',\n",
       " 'huge',\n",
       " 'mountain']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  단어 집합 words 생성. sentences에서 문장의 경계인 [, ]를 제거\n",
    "words = sum(sentences, [])\n",
    "words\n",
    "\n",
    "# import numpy as np\n",
    "# words = np.hstack(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bad76bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'barber': 8,\n",
       "         'person': 3,\n",
       "         'good': 1,\n",
       "         'huge': 5,\n",
       "         'knew': 1,\n",
       "         'secret': 6,\n",
       "         'kept': 4,\n",
       "         'word': 2,\n",
       "         'keeping': 2,\n",
       "         'driving': 1,\n",
       "         'crazy': 1,\n",
       "         'went': 1,\n",
       "         'mountain': 1})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Counter(words)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f1ca3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "vocab = vocab.most_common(vocab_size) # 빈도수 상위 vocab_size 리턴\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17945c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}\n"
     ]
    }
   ],
   "source": [
    "# 정수 인덱스 부여\n",
    "word_to_index = {}\n",
    "i = 0\n",
    "\n",
    "for (word, frequency) in vocab:\n",
    "    i += 1\n",
    "    word_to_index[word] = i\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34444d70",
   "metadata": {},
   "source": [
    "# NLTK FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb7f66da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "065698ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'barber': 8, 'secret': 6, 'huge': 5, 'kept': 4, 'person': 3, 'word': 2, 'keeping': 2, 'good': 1, 'knew': 1, 'driving': 1, ...})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = FreqDist(np.hstack(sentences))\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96ec466d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['barber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e119546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('barber', 8), ('secret', 6), ('huge', 5), ('kept', 4), ('person', 3)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "vocab = vocab.most_common(vocab_size)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f60931b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barber': 1, 'secret': 2, 'huge': 3, 'kept': 4, 'person': 5}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enumerate 이용\n",
    "word_to_index = {word[0]: index+1 for index, word in enumerate(vocab)}\n",
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "830f774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: a, index: 0\n",
      "value: b, index: 1\n",
      "value: c, index: 2\n",
      "value: d, index: 3\n",
      "value: e, index: 4\n"
     ]
    }
   ],
   "source": [
    "# Enumerate()\n",
    "# 순서가 있는 자료형(list, set, tuple, dictionary, string)을 입력받아 인덱스를 순차적으로 함께 리턴.\n",
    "test=['a','b','c','d','e']\n",
    "for index, value in enumerate(test):\n",
    "    print('value: {}, index: {}'.format(value, index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e2b700",
   "metadata": {},
   "source": [
    "# Keras tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f0c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8a77db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barber': 1,\n",
       " 'secret': 2,\n",
       " 'huge': 3,\n",
       " 'kept': 4,\n",
       " 'person': 5,\n",
       " 'word': 6,\n",
       " 'keeping': 7,\n",
       " 'good': 8,\n",
       " 'knew': 9,\n",
       " 'driving': 10,\n",
       " 'crazy': 11,\n",
       " 'went': 12,\n",
       " 'mountain': 13}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences) # 단어 빈도수가 높은 순으로 낮은 정수 인덱스 부여\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7d4be5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('barber', 8),\n",
       "             ('person', 3),\n",
       "             ('good', 1),\n",
       "             ('huge', 5),\n",
       "             ('knew', 1),\n",
       "             ('secret', 6),\n",
       "             ('kept', 4),\n",
       "             ('word', 2),\n",
       "             ('keeping', 2),\n",
       "             ('driving', 1),\n",
       "             ('crazy', 1),\n",
       "             ('went', 1),\n",
       "             ('mountain', 1)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts # 단어수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1624d45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [1, 8, 5],\n",
       " [1, 3, 5],\n",
       " [9, 2],\n",
       " [2, 4, 3, 2],\n",
       " [3, 2],\n",
       " [1, 4, 6],\n",
       " [1, 4, 6],\n",
       " [1, 4, 2],\n",
       " [7, 7, 3, 2, 10, 1, 11],\n",
       " [1, 12, 3, 13]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(sentences) # 입력으로 들어온 코퍼스에 대해 각 단어를 이미 정해진 인덱스로 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e95a4f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'barber': 1,\n",
       " 'secret': 2,\n",
       " 'huge': 3,\n",
       " 'kept': 4,\n",
       " 'person': 5,\n",
       " 'word': 6,\n",
       " 'keeping': 7,\n",
       " 'good': 8,\n",
       " 'knew': 9,\n",
       " 'driving': 10,\n",
       " 'crazy': 11,\n",
       " 'went': 12,\n",
       " 'mountain': 13}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "tokenizer = Tokenizer(num_words=vocab_size+1) # 상위 5개 단어만 사용\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "tokenizer.word_index # 13개가 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c5db4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('barber', 8),\n",
       "             ('person', 3),\n",
       "             ('good', 1),\n",
       "             ('huge', 5),\n",
       "             ('knew', 1),\n",
       "             ('secret', 6),\n",
       "             ('kept', 4),\n",
       "             ('word', 2),\n",
       "             ('keeping', 2),\n",
       "             ('driving', 1),\n",
       "             ('crazy', 1),\n",
       "             ('went', 1),\n",
       "             ('mountain', 1)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52ebd6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5],\n",
       " [1, 5],\n",
       " [1, 3, 5],\n",
       " [2],\n",
       " [2, 4, 3, 2],\n",
       " [3, 2],\n",
       " [1, 4],\n",
       " [1, 4],\n",
       " [1, 4, 2],\n",
       " [3, 2, 1],\n",
       " [1, 3]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(sentences) # 상위 5개 지정은 texts_to_sequences 호출 시 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1de6959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 OOV의 인덱스: 1\n"
     ]
    }
   ],
   "source": [
    "# OOV 처리\n",
    "vocab_size = 5\n",
    "tokenizer = Tokenizer(num_words=vocab_size+2, oov_token='OOV') # 상위 5개 단어만 사용\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "print('단어 OOV의 인덱스: {}'.format(tokenizer.word_index['OOV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc3a83dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 6],\n",
       " [2, 1, 6],\n",
       " [2, 4, 6],\n",
       " [1, 3],\n",
       " [3, 5, 4, 3],\n",
       " [4, 3],\n",
       " [2, 5, 1],\n",
       " [2, 5, 1],\n",
       " [2, 5, 3],\n",
       " [1, 1, 4, 3, 1, 2, 1],\n",
       " [2, 1, 4, 1]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(sentences) ## OOV는 1로 인덱싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592ff9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
